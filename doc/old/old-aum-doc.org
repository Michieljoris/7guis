#+TITLE: #+OPTIONS: toc:4
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="stylesheet.css" />
* Read first
There are two somewhat diverging versions of bilby-libs. The pre templates
version runs well, and is quite flexible, however to more easily implement the
templates editor I have reworked the frontend om-next parser somewhat. Below is
docs for the templates version. It is quite possible to refactor/merge new
features for current production to the templates version, however it is slightly
cumbersome. So the plan/goal is to get the templates version up to production
stability and reliability, with the templates editor disabled till it's ready to
be used. This will greatly simplify adding new features, bug fixes, writing
documentation etc while templates editor is getting ready to be used.
* Documentation for bilby-libs
** Getting started
*** Useful docs to read first
**** React
 https://reactjs.org/docs/getting-started.html

 Om-next is built on react. Om-next components are basically classical react
 components with a layer over them so om-next can do it's own optimisations and
 control the render cycle. But just like in react you have access to the various
 lifecycle hooks (but leave shouldComponentUpdate alone, this is managed by
 om-next). You pass in props to subcomponents and components can have their own
 local state. Basically om-next generates a tree of data from the app-state by
 applying the root query of the app over it every time a transact is done or a
 merge of data with app-state (in the reconciler for instance when data is
 returned and the callback invoked with it). This data is then supplied to the
 root component and the new ui state calculated and rendered. Which is then
 static till the next transaction or merge. This sounds rather inefficient, but
 the way React is designed it's not in practice. Also om-next itself won't even
 ask React to re-render a component if it decides that the props that are passed
 to it haven't changed from the last time it was rendered.
**** Om-next
[[https://github.com/omcljs/om/wiki/Documentation-(om.next)][https://github.com/omcljs/om/wiki/Documentation-(om.next)]]
**** Fulcro handbook
 http://book.fulcrologic.com/
 Most of it is about how om-next itself works. The solutions for a more practical
 om-next are a bit different, and in some ways diverge somewhat from the 'om-next
 way' of doing things.
**** See om-next docs for more useful links
 Such as for graphql, falcor, datomic etc.

 Om-next by leveraging lisp and immutable values combines the best ideas of
 graphql and falcor in a less cumbersome and more flexible manner.

*** Install
See readme of repo.
*** Starter app
TODO (needs updating)
There is a repo that's an app using bilby libs, but has no admin content. This
can be used to try out building features/pages without having to deal with the
added complexity of the current admin app.
** Core concepts
*** It's om-next.
The idea is to stay as close as possible to the original idea of om-next as just
a thin layer on the top of react, but extend some concepts so at the very least
a straightforward crud app can be built really simply and quickly, with simple
tools to facilitate both front and backends development.

Om-next itself is isomorphic, meaning it can ran on either front or backend.
Bilby-libs extends om-next to some extend, and a some of it can be used
anywhere, but in general it focuses more on making om-next useful in a practical
way. So in the backend the om-next parser is implemented to query a mysql
database, with security and validation mechanisms.

On the frontend bilby-libs implements a parser that in most cases will do the
right thing in denormalizing queries over the app state. And there are mechanism
for dealing with multiple remotes, websockets, error handling, correcting
optimistic updates etc.

Bilby-libs has its own thin layers over the reconciler and parser but still uses defui, om/transact! etc

** Backend and frontend
*** Generic save records
When you have a page with records including their joins recursively you might
want to save the whole lot in one hit. Bilby-libs calculates the actual
modifications, and only sends what's changed to the backend. The backend then
will save these records in the right order, taking into account newly created
records and any dependencies on them and will if anything went wrong with
updating a record return this info per record. It garantuees to leave the db in
a consistent and validated state and returns enough information so the frontend
can correct any optimistically updates to its own app state and make sure it's
stays in sync with the backend.
*** Have backend return calculated data

  There are three ways to do this:

**** Calculate something over a (sub)query
   Sometimes you want something to be calculated over a query and return not only
   the rows themselves, but also the extra data, such as total count. This is
   particularly tricky if you want to calculate something over a join. You want
   the joined rows, but also some more data over that particular subset of rows
   (joined as they are to the parent record).

   To do this add a :with-meta param key to the params of the query. Set this to a
   single keyword or map or a vector of them. If it's a map it should have at
   least a key :type, but you can then add more params for the calculation if you
   want.

   You can then extend the calc-meta-data multimethod from
   bilby.parser.calc-meta-data in the backend which is dispatched on those
   :with-meta keys, or the :type value if it's a map. The method is called after
   the original sql query has been done. The sql-fn called, its args and
   calc-params as passed from the frontend.

   #+BEGIN_SRC clojure
  [{:group [({:user [:id :name]} {:with-meta [:count {:type :calc2 :some :params}]})]}]
  #+END_SRC

  #+BEGIN_SRC clojure
  (defmethod calc-meta-data :count
    [env rows {:keys [sql-fn sql-fn-args return-empty-vector? join-type calculation-params]}]
    ;;Do your calculation here
     )
  #+END_SRC

  One thing to take note of is that the return value for this query will be now of
  the form:

  #+BEGIN_SRC clojure
  {:rows [[:id 1 :name "foo"]] :meta {:count 123}}
  #+END_SRC

  Which means you will have to take this into account when this data arrives at
  your component, and/or when you implement the read method for the join with the
  :with-meta param.

**** Define a read key in the backend

  Such as:

  #+BEGIN_SRC clojure
  (defmethod bilby/read :calc/count
    [{:keys [user state parser query parser-config] :as env} _
     {:keys [table where] :as params}]
    ;;You can use the query to decide on what to calculate perhaps
    (timbre/info query) ;;=> [:count]
    {:value {:count (count-records env params)}})
  #+END_SRC

  Then add a query to a component:

  #+BEGIN_SRC clojure
  ({:calc/count [:count]} {:table :user
                           :where [:id :< 5]})
  #+END_SRC

  Disadvantage of this method is that you can only use this query as a root query
  or quasi root query. Also you have to possibly duplicate the params of this query in the
  frontend from another query. And this isn't useful for a joined query.

**** Redirect a read to a custom-read
  Used search translations. Idea is to set a :custom-read key in the params of a
  query. Backend will use the read method as set to the :custom-read key and pass
  in the rest of params as well.

  Advantage of this is that you can redirect a query for a join to your own read
  method. Where you can then return a calculated value, any rows queried for
  and/or any other data you like.

  #+BEGIN_SRC clojure
  (defmethod bilby/read :count-records
    [{:keys [user state parser query parser-config] :as env} _
     {:keys [table where] :as params}]
    {:value (count-records env params)})
  #+END_SRC

  With this query:

  #+BEGIN_SRC clojure
  '({:user-count [:count]} {:custom-read :count-records
                            :table :user
                            :where [:id :< 5]})
  #+END_SRC

*** Config
You can use the bilby-app.config/config multimethod to return and easily,
flexibly and succinctly query for any config in your app. Front and backend have
invariable different configs, but some of it is shared perhaps, this can be
pushed to the frontend with a macro. Also you might want to run frontend
namespaces in the backend and/or backend namespaces in the frontend (in tests or
while developing). By using a config multimethod this is abstracted and can be
adjusted and implemented on a case by case basis as you are testing/developing.

** Backend
*** Use datomic pull syntax to query mysql database
Use om-next queries to do crud on any mysql database, where the read can
use one or more joins from and to any table, constrained only by the
(db-)configuration of the parser.
*** Security
Bilby comes with login and logout fns for both front and backend. However in
production this is disabled and users are directed to the rails app.
The remember token as set by the rails app is used to authenticate the session
similar to how it's done in the rails app. One complication is that because how
sente/websockets work is that to renew the session and any attached remember
token the connection has to be renewed.
*** Internationalization
There is a common.i18n.cljc namespace which provides the translate fn which
takes the current locale and a key.
*** Websockets
*** Write validation
A generic sql query fn that garantuees validation (doesn't work if not
implemented) of the query with hooks for pre processing the params of the query
and post processing of the result of the query.

**** Sql validation
 Every call to the sql fn in the database.query ns by default is validated by
 calling the bilby validate-sql-fn multimethod. This dispatches on sql fn
 keyword. For all mutating sql queries as defined in the bilby.database.queries
 ns the proper validation fn is retrieved using security/get-validation-fun.
 This can be set in the database.config but if not the multimethod
 bilby.database.validate.core/validate multimethod is called, dispatching on
 role of the user, method (sql fn keyword) and table.

Idea is that for every hugsql fn added you will have to write a validate-sql-fun
 method otherwise it will just throw an exception when its called through
 database.query/sql. You can write an empty method, and then no validation is
 done. You can do validation right there and then, or you can retrieve an
 appropriate validation fn by calling security/get-validation-fun. You will
 probably wil have to add a fn to database.config or add an appropriate
 bilby.database.validate.core/validate method. Otherwise, again, an exception is
 thrown by default.
**** Sql process-params, process-result
In essence all the database.query/sql fn does is first call
bilby-process-params, then process-params on the params, call validate-sql then
call the actual hugsql fn and then call bilby-process-result and then
process-params on the result.

bilby-process-params does some built-in params processing, same for
bilby-process-result. Custom versions of these fns will be used if set in the
sql prop of env.

process-params does nothing by default, process-result just returns result as
passed in.

bilby.database.queries ns is used to resolve the hugsql fn

It's also possible to add an extra hugsql ns for resolving the sql fn.
(bilby-)process-params, (bilby-)process-result and validate-sql-fun are all
multimethods so you can add methods to deal with any extra hugsql fns.

process-params (and process-result) is handy for adding hooks. For instance for
the event-store. For more detail see also doc string of database.query/sql fn.
** Frontend
*** Use pages to organize your ui
There are some basic fns for this. See app.pages for how to add a page.
*** Client only keys
Any key with a namespace that starts with :client will never be sent to the
backend. The value for any key with the namespace :client will be looked up in
the root of app state.
*** Validation of form values
When doing a save of a record on a particular page bilby-libs looks in the app
config for that page a validation function for every prop of the record. If any
prop is not 'valid' it's added to the client/invalidated-fields map of the state
for that page (under the table key for that record). This can be queried for in
the relevant component and used to set any ui flags and/or messages for that
field.

TODO:
Currently this happens when a record gets saved, but it's possible to add a
mutation that does this on demand, for instance on onBlur..
*** Syncing of front and backend
All records have as their meta data something like this:
#+BEGIN_SRC clojure
  {:record {:id 1 :type :foo :name "bar"} ;;record as it came from the servr
   :uuids [] ;;history keeping
   :prev-uuid nil}
#+END_SRC
The meta record map is nil unless something has been modified in the record
itself. The various uuid keys are used for undo/redo functionality. They are
references to a particular state in the history of states for the app as kept by
om-next.

Reverting a record is as easy as replacing with its meta record. Calculating
what has changed to a record for purposes of sending modification to the backend
is doing a diff. And to decide whether its 'dirty' bilby-libs in essence just
does a comparison.

It's possible for example to reset just the one prop of a record as a result of
clicking a 'reset' button in the component for that field. The original value
can always be fetched from the meta record.
*** Generic recursive read with hooks
**** Intro
***** Combining queries
In om-next the root query is composed of sub queries recursively as they're
pulled from components. However not every component necessarily represents a
database row, or sequence of rows of a database table. Sometimes a component is
just a grouping of other components. These components still need their own
queries. A natural way of doing that is to use placeholder keys. Both front and
backend parsers skip over these keys and just keep parsing and trying to return
values for deeper lying keys instead. In the case of the backend if a key is not
a table as set in the database config it will ignore it. In the frontend the
parser just grabs the value of the key if it exists in the app state and keep
parsing.
***** Finetuning parser result
In om-next for every render the complete root query is applied over the
app-state (basically the same as the om-next function db->tree). This works fine
for a small and simple app, however as an app gets more complicated you would
like to have a bit more control of what gets returned for a key and/or if a key
is included in any remote query. A standard om-next parser only implements
reading the root query keys. In other words, it's not recursive. The bilby-libs
parser recursively tries to interprete a query and will call any hooks for keys
if they exist. So at any time during the parsing of a query you can insert your
own code for resolving values and any remote. If you want to keep resolving any
deeper lying queries you can call the supplied db->tree passed in the env
(similar to how you received the parser in standard om-next).

Standard om-next has something like dynamic queries. This extends this idea by
letting you respond to app-state changes and changing what gets returned for any
key anywhere in a query for both value and any remote. For instance you can set
the selected-id in app state to 123 and in the query for your record in your
'selected-item' component adding the right parameters to the query that goes to
the backend. This should return the selected item once it's been fetched, but if
you want you could customize that value as well, for example because you want to
calculate a client side prop and add it to the value. Requesting and returning
batches of items can be implemented similarly.

**** Adding hooks for keys and joins in the root query for returning values and building remote query
***** Principles
   The standard read method of bilby is db->tree of om-next. This will return a
   tree of data by applying the root query over the app-state. The stock om-next
   db->tree fn has been extended in the following ways:

   1. It's possible to define read methods for any key anywhere in the query. If
      you do you can then return anything you want for that key. You will get in
      the env the ast for the om-next expression (join or prop), the query if it's
      a join, context-data and (app-)state. Context data is the data relevant for
      the prop or join, which depends on where in the root query the key for the
      join or prop is. For instance the default way to resolve a prop is just to do
      (get context-data key). Default way to resolve a join is db->tree on the
      query and context-data (see bilby.reconciler.parser.key.route and the read
      method for [:value :route/*]).

   2. The db->tree fn has been modified so that it instead of returning data it'll
      return the query again, but 'sparsified' when :sparsify-query? flag is set.
      By default if any data is found that part of the query is elided. But again
      you can add read methods to determine yourself if and what should be included
      for any key in the root query. In standard om you need to return a (possibly
      modified) ast. For these bilby read methods to work you return a (modified)
      query instead. Whatever you return will be included in the remote query. If
      you want to process and modify the ast you can you just do a (om/ast->query
      ast) when you're done editing it. You can also return true which will then
      result in the query being parsed further the standard db->tree way. Note that
      currently if the key is a prop only the truthiness of the return value is
      used. If truthy the return key is included, otherwise it isn't. Return the
      full query in case of a join. So for a read method for [:bilby :foo] you
      return {:foo [:some :query]}. If query had params you can add them again,
      possibly modified.

   3. Read method is dispatched on key, or on [target key]. Second one takes
      preference over first. In the first instance you need to return a map such as
      {:value :some-value :bilby {:some-key [:some :query]}} similar to standard
      om-next read methods.

***** Examples
****** VALUE example
   The method (note the :value in the dispatch vector):

   #+BEGIN_SRC clojure
   (defmethod bilby/read [:value :bar] [{:keys [query context-data] :as env} key params] ...)
   #+END_SRC

   for a app state structure like this:

   #+BEGIN_SRC clojure
   {:foo {:bar {:k1 1 :k2 2}}}
   #+END_SRC

   and a root query of:

   #+BEGIN_SRC clojure
   [{:foo [{:bar [:k1 :k2 :k3]}]}]
   #+END_SRC

   receives env like this:

   #+BEGIN_SRC clojure
   {:query [:k1 :2]
    :context-data {:k1 1 :k2 2}
    :ast {:type :join, :dispatch-key :bar, :key :bar, :query [:k1 :k2],
          :children [{:type :prop, :dispatch-key :k1, :key :k1} {:type :prop, :dispatch-key :k2, :key :k2}]}
    ...
   }
   #+END_SRC

   and should return for example this:

   #+BEGIN_SRC clojure
   {:k1 1 :k2 2}
   #+END_SRC

****** REMOTE example
   The method (note the :bilby in the dispatch vector):

   #+BEGIN_SRC clojure
   (defmethod bilby/read [:bilby :bar] [{:keys [query context-data] :as env} key params] ...)
   #+END_SRC

   for a app state structure like this:

   #+BEGIN_SRC clojure
   {:foo {:bar {:k1 1 :k2 2}}}
   #+END_SRC

   and a root query of:

   #+BEGIN_SRC clojure
   [{:foo [{:bar [:k1 :k2 :k3]}]}]
   #+END_SRC

   receives env like this:

   #+BEGIN_SRC clojure
   {:query [:k1 :k2 :k3]
    :context-data {:k1 1 :k2 2}
    :ast {:type :join, :dispatch-key :bar, :key :bar, :query [:k1 :k2],
          :children [{:type :prop, :dispatch-key :k1, :key :k1} {:type :prop, :dispatch-key :k2, :key :k2}]}
    ...
   }
   #+END_SRC

   and should return for example this:

   #+BEGIN_SRC clojure
   {:bar [:k3]}
   #+END_SRC

   to create a remote query like this:

   #+BEGIN_SRC clojure
   [{:foo [{:bar [:k3]}]}]
   #+END_SRC

   If you want to keep the params (or add, or modify) return something like this:

   #+BEGIN_SRC clojure
   (cond-> {:bar [:k3]}
     (some? params (list params)
   #+END_SRC

****** Routing

 Sometimes you would like to only load (send with the remote) a particular
 segment of a root query, for instance based on route of page that the user
 selected to display. By setting the selected page in app state you can (by using
 key inheritance and multimethods) only return a remote for a key that matches
 that page:

 #+BEGIN_SRC clojure
   (defmethod bilby/read [:value :page/*]
     [{:keys [state default-remote context-data query db->tree] :as env} page params]
     (let [current-page (:app/page @state)]
       (when (= current-page page)
         (db->tree env {:query query
                        :data  context-data
                        :refs  @state}))))

   (defmethod bilby/read [:remote :page/*]
     [{:keys [state] :as env} page params]
     (let [current-page (:app/page @state)]
       (= current-page page)))

     (doseq [page [:page/some-page :page/some-other-page]]
       (bilby/derive-om-query-key! page :page/*))
 #+END_SRC

This implements basic 'routing'.

This is
****** Pagination
Set the query for the items you want to display paginated (or with infinite
scroll) in the relevant component. This will by default fetch all available
records (or as many as the server is willing to send in one batch). This is not
what we want so we add a hook for the query for that component. In that query we
add the proper params (such as limit, offset etc). These values will (should)
have been set in app state with a mutation (triggered by a scroll or click of
pagination button). Now only the records for a particular page are fetched. If
we are paginating this is enough. If we are scrolling we need to 'cache' the
list of idents already in place for our key from a previous query. Then on read
of that key we need to prefix the cached list of idents to the actual list of
idents received from the backend.
****** Autocomplete
Add a hook for the key for the autocomplete component. Return nil for any remote
and it will not be added to the root remote query Once a search term is set in
app state we adjust the query for the autocomplete component and add the right
params (eg. {:where [:name :like "%my search%"]}). This will make data avaliable
for the autocomplete component to display in its dropdown. This search term in
app state will have to cleared when navigating away from the page otherwise it
will be acted on again when returning to the page with the autocomplete.
***** Notes
- If you set ignore-hooks? to true db->tree will function as the standard om-next
db->tree, but by setting :sparsify-query? to true you can still also calculate
the remote query.

- In bilby.reconciler.parser.denormalize there's a comment block where you can
play around with db->tree. There's also the try-frontend-read ns.

- To see the whole process in all its glory set timbre-level to :debug in
app.config.cljs and set the chrome dev console to verbose output.

_ For read methods the parser is not available in the env, but db->tree is.

Use of that is simple:

#+BEGIN_SRC clojure
     (db->tree env {:query query ;;Apply this query
                    :data  data ;;to this data
                    :refs  app-data ;;looking up idents (refs) here.
                    :sparsify-query? false ;;Return the data, not a sparsified query
                    :ignore-hooks? false
})
#+END_SRC


*** Security
There's login/logout methods in app/security.cljc. Disabled in production.
*** Garbage collection
There is currently no garbage collecting implemented. As with any garbage
collection the criteria for this are rather app and platform specific. But in
principle you will only have to delete any data from app state and if the ui
gets in a state where it requires that data it will just be added to any remote
query again.

A history of all app-state is kept, this is limited to 100 by default. This
could be reduced. On page change you could just wipe any idents referred to
by that page.
*** Internationalization
There is a common.i18n.cljc namespace which provides the translate fn which
takes the current locale as passed into components as a computed property and a
key.
*** Post remote
Sometimes you would like to a take some extra action _after_ a remote mutation has
finished and the data has been returned. For every mutation method you can
define a same name post-remote method. This is called with the value as returned
from the backend. Here you can do error handling for instance or 'clean up' the
response before it get merged with app state.
*** Pre-merge hooks
These hooks allow you to take action before _any_ value gets merged with
app-state, including responses to read queries.
*** Merging pushed data
Backend can use websockets for resolving queries from the frontend, but this
means it's also possible to 'push' data. The frontend can  respond to this and
merge this as any regular response to a query. This is useful to keep instances
of the app in sync, but also to show notifications, or to push a response of a
query in an async manner. It can be sent to the frontend if and whenever the
required data is available.
*** Generic undo/redo/revert.
Every mutation on a record adjust some metadata on the record that enables
undo/redo/revert for that record. This also includes any data joined to that
record, they will also get undone/redone/reverted.
*** Run backend in frontend (for testing for example)
It is possible to run the whole backend in the frontend where the mysql database
is 'mocked' in the frontend. This is ideal for writing integration tests
covering the whole stack
*** Test runner
Standalone client-side om-next test-runner app to be used with the
alternative test macros that add and remove tests to the lists of tests. Several
ways to display diffs. Rerun test on click. Use snapshots for any test instead
of writing the required result into the test. Helpers to click and compare html
output for acceptance ui tests. Replay/rewind/step through (ui) tests by using
pause macro.
*** Snapshot testing
There are facilities to create a test by putting it together step by step and
instead inserting expected results take snapshots and use them instead. This is
particularly handy for testing states of the ui. It's also then possible to step
through the test in the test runner. If any intermediate snapshot fails the test
but (because we updated the code for example) is what we do expect we can update
the snapshot by clicking a button.
*** Whole stack testing
By combining test runner, snapshot testing and running backend in frontend it's
possible to do whole stack testing.
*** Inspector
Search, filter and drill into app state.
*** Dev-cards
    Switch to dev cards page from app itself.
** Misc
*** Querying other sources than a mysql database
**** Using more than one remote in the frontend
Example: lawcat
**** Returning data fetched from another source
Example: tent
**** Integrating pathom
*** Trying queries
In the dev source folder there are namespaces to try out various queries:
**** try-om-query
You can call the backend parser with any om-next query. These are resolved
against the database as defined in app.config and using database.config as
defined for the whole app.

There is a second version where you can build your own parser environment and
your own parser with that again.
**** Try sql query
To try out any sql query. Make sure to define process-params, validate-sql-fn
and process-result methods, and the equivalent sql fun in build-sql if you want
it to be used in mock mode or tests.
**** Try/test frontend parser.
Frontend parser is a cljc file so you can eval this in a clojure repl. You can
test here what the parser returns for queries for the nil and various remote
targets, which is much harder to test/inspect if you have to use the ui to pass
queries to the parser.
*** Fixtures per test
    It's possible to set up a context for one more tests to run in. Inside the
    macro call `in-context` you'll have access to tu/*env* which will be set
    properly according to the context you're in. The *env* has db-conn which you
    can use directly or you can use the a parser or bilby.database.query/sql and
    pass in *env*. For your convenience two more dynamic variables, tu/*parser*
    and tu/*state* are bound while 'in-context' using the parser-config and
    db-config passed in when creating a context using tu/make-context.

#+BEGIN_SRC clojure
  (require
   '[bilby.app-config :refer [config]]
   '[clojure.test :refer [deftest is]]
   '[bilby.test.util :as tu :refer [debug-tests unload-all-tests unmap-all-interns in-context truthy?
                                    make-context query]]
   )


  ;;This will create just the one table, foos, with just one row.
  (def fixtures {:foos {:rows [{:id 1 :title "bar"}]
                        :options {:id-primary-key? true}
                        :schema {:id :int :title :text
                                 :updated-at :date-time :created-at :date-time}
                        }})

  (def my-db-config
    {:root true
     ;;by default you can refer to a table by its singular name (the end s is
     ;;removed from the table-name).
     ;; :table-name :foo :columns
     (keys (get-in fixtures [:foos :schema]))
     ;; :joins {:bar {:t1-foreign-key :bla-id}}
     :read {:role {"super-admin" {:blacklist []}}}
     ;;NOTE: For update, create, delete mutations you'll might have to create the
     ;;appropriate validations as well.
     :update {:role {"super-admin" {:blacklist [:id :updated-at :created-at :creator-id]}}}
     :create {:role {"super-admin" {:blacklist [:id :updated-at :created-at]}}}}
    )

  (def context-foo
    (make-context
     {:db-config {:foo my-db-config}
      ;;Or use config from your app:
      ;;:db-config (select-keys database.config/db-config [:user])
      :parser-config (merge (config) {:allow-root true :print-exceptions true
                                      :sql-log true :query-log true
                                      :event-store-disabled true})
      :fixtures fixtures}))

  (def user {:id 1 :some-user "a-user" :role "super-admin" :group-id 10 :subgroup-ids [-1]})

  (in-context context-foo
    (tu/*parser* (assoc tu/*env*
                        :user user)
                 [{:foo [:id]}]))

#+END_SRC

* Not boot, not lein but clj-tools to develop and build the app
All dependencies are declared in deps.edn. For executing various tasks for
developing and building the app, and for creating a development environment
[[https://github.com/mbuczko/revolt][revolt]] is used. Its configuration is in resources/revolt.edn. Various custom
tasks are defined in bilby.revolt namespaces. Figwheel has its own config in
figwheel.main.edn main.cljs.edn. At the moment the cljs compiler config is
duplicated in revolt.den and main.cljs.edn. It's on the todo list to fix that.
It all comes together in the build and run scripts in the bin dir.
* DC admin code outline
** Backend
The app uses websockets (library is sente) to communicate with the backend. In
web-server.handler/handler there is a request handler added using
web-server.routes/routes which deals with routes for dashboard, resources for
the admin app itself, but also with a sente-route as defined in
websockets.core/sente-route. This sente route handler forwards any messages to
the multimethod websocket.dispatcher/event-msg-handler. Regular messages from
the frontend are of type :admin/query, dispatched to handle-admin-query. This fn is
the main handler of om-next queries and mutations as sent by the frontend.

For every websocket request first the user is fetched by remember-token as set
on the (websocket) request. This user is added to the env given to the parser
together with the om-next query.

The result of this parser call is then sent to the frontend by the reply-fn as
supplied by sente. Some added complexity stems from the fact that the code can
run in frontend for testing purposes. Also a callback fn is added to the env so
any handler code of queries can send data to the frontend asynchronously

There's login and logout handlers in this namespace, but this is disabled in
production mode.


Parser and parser env is defined in parser.core as a mount.core state. The
actual parser and its env is created in bilby.parser.

The om-next read and mutate multimethods are defined in bilby.parser.read and
bilby.parser.mutate.

The bilby mutate multimethod deals with basic save-record and delete-record.
This uses validation methods as defined in db-config to control access. Further
mutate methods are defined in the app's parser.mutate ns.

There are a few read methods in parser.read, but the bulk of frontend queries is
dealt with in bilby.parser.read ns. This namespace is a generic parser and
interpreter of om-next queries. It tries to resolve this query using the mysql db
as configured in the env.In essence it's a recursive resolver. It uses just a
few predefined, parameterized sql queries defined using the hugsql library
(get-cols-from-table and get-joined-rows). Tables in the database need to be
configured in db-config in the env, otherwise access is denied.

Some features (some controlled by parser-config):
- :om-process-roots (boolean)
  If a key in a join is not recognized as a db table it is
  ignored. So a query like: [{:foo [{:user [:id]}]}] will return for example:
  {:foo {:user [{:id 1} {:id 2}]}}. If this om-process-roots is true the query
  will fail because it will expect :foo to be a valid db table. This is rather
  handy for frontend query building since we can insert multiple 'placeholder',
  or 'dummy' keys before querying for table data.
- :limit-max (number)
  Since we can basically query the db (within the constraints as set by
  db-config) freely, and from join to join we can end up with a lot of data.
  Set to 100 by default, this prevents this from happening to some degree.
- :derive-join-type-from-schema (boolean)
  For instance [{:template [{:user [:id]}]}] will look for a table
  templates-users to resolve the join.
- normalize (boolean)
  Whether to return table data in-lined or in a table/by-id map
- When a table query has params such as {:with-meta :count} the query is
  resolved normally, but also all data (query-fn, params etc) is handed over to
  a multimethod calc-meta-data. Any data returned from this multimethod is
  combined with the result of the query itself in a map like this:
  {:rows [..] :meta ....}. Frontend will have to take this into account and pry
  the relevant data out in the appropriate read methods.
- It's possible to set aliases for tables in db-config. Handy for renaming
  tables, having multiple joins to the same table etc.
- It's possible to write your own (read method) resolver for a join by adding :custom-read key
  and value to the params of a query.
- In general, the parser tries to do the expected thing, but when there's
  ambiguity, or a query is not properly formulated it will throw an error,
  caught in the default read method.
** Frontend
*** app.core.cljs
app/core.cljs is where the app is mounted and started.

To get around some cyclical namespace issues we implement a channel, and start a
channel listener. The websocket is started by calling websocket.core/start!.
This forwards any messages to the multimethod
websocket.dispatcher/websocket-msg-handler. What we're mainly interested in is
the :chsk/state and :chsk/recv sente websocket messages. The first one will let
us put a msg on the app channel about websocket status, which can then be
processed by the app. The :chsk/recv we use for picking up any data pushed to
the app from the server.

Once websocket is up and connected we actually mount the app, which starts the
om-next cycle of taking the app state, hydrating the ui with them, responding to
mutations and again reading app-state etc. Any read methods returning a remote
ast will trigger reads on the backend.

Frontend similar to backend tries to resolve om-next queries in a generic way in
bilby.reconciler.parser.read in the current production admin. This is a kind of
kitchen sink read method, and tries to send only queries for properties that are
not yet in the frontend app state. To have conditional backend queries (eg
autocomplete) the mechanism of set-params is used. In the templates branch the
om-next/db->tree is actually rewritten so it's possible to create read methods
for any key in the query tree, which is much more flexible and easier to
understand. The whole bilby.reconciler.parser.read namespace is thus not needed
anymore.

*** Basic structure of an admin page.
A standard admin page is very often a basic crud ui. Since this is so standard
it's abstracted somehow by the defcmp macro. It sets up a selectable, scrollable
list of records on the left, with a form on the right. It can be extended to
some degree, but for a more flexible layout and functionality it's better (and
much easier) to just start from scratch (examples are templates and dossier type
admin pages).

First step is in both cases to add your new page to app.pages ns. This should
get you an entry in the pages dropdown. There is a default admin page you can
use as a template and starting point. When building a page the practice is to
build your ui up to some degree, including queries on any components. If data is
not returned from the backend you should use try-om-query.clj in your repl and
test your whole or partial queries that are not working. Most often there is an
error in your query, or the database config is not letting you fetch the data
(yet). In general you should not have to adapt or write any code for the backend
other than updating db-config and writing mutations. Of course there are always
edge cases. However for the ones I've encountered so far I have been able to
adapt the generic backend parser to accommodate these non standard requests. One
is for example using self joins (use aliases), or returning extra data (use meta
data mechanism), there are a few more as added over the years.

The biggest trick is to write proper read methods. (Or the set-params mechanism
in older bilby-libs versions). In general you always want to return what's in
app-state, but not always trigger a remote query if data is not present in the
frontend, however sometimes you do still. By setting flags and data in app-state
it's possible to steer/control these read methods somewhat based on what's
happening in the ui (this is similar to om-next dynamic queries, but much more
explicit and transparent for the programmer to use). For instance in the
template editor there is a massive recursive query for the whole of the ui. If
sent as is to the backend it would theoretically return every template, category
and question in the db (but backend has some limits set to that in practice).
However initially you only want to load the top templates. And only a subset if
you're paging. Once a user clicks on template, only then do you want to download
any linked categories and questions. And even then perhaps only partial data for
these linked records, such as name, but not any other data. By carefully writing
read methods for these joins and keeping track in app state of what the state of
the page is it's possible to have fine control over what gets actually sent to
the backend as a query.
*** Misc notes on code
**** Update ui on save
 Figwheel picks up any changes to namespaces and calls my-after-reload-callback
 in user.cljs. All that does is update :client/reload-key to a new random value.
 This key gets queried for in the root component and as long as this key gets
 passed into components (as a computed prop preferably) om-next will then force
 update all those components.old-aum-doc
