#+TITLE: #+OPTIONS: toc:4
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="stylesheet.css" />

* Getting started
** Useful docs to read first
*** React
 https://reactjs.org/docs/getting-started.html

 Om-next is built on react. Om-next components are basically classical react
 components with a layer over them so om-next can do it's own optimisations and
 control the render cycle. But just like in react you have access to the various
 lifecycle hooks (but leave shouldComponentUpdate alone, this is managed by
 om-next). You pass in props to subcomponents and components can have their own
 local state. Basically om-next generates a tree of data from the app-state by
 applying the root query of the app over it every time a transact is done or a
 merge of data with app-state (in the reconciler for instance when data is
 returned and the callback invoked with it). This data is then supplied to the
 root component and the new ui state calculated and rendered. Which is then
 static till the next transaction or merge. This sounds rather inefficient, but
 the way React is designed it's not in practice. Also om-next itself won't even
 ask React to re-render a component if it decides that the props that are passed
 to it haven't changed from the last time it was rendered.
*** Om-next
[[https://github.com/omcljs/om/wiki/Documentation-(om.next)][https://github.com/omcljs/om/wiki/Documentation-(om.next)]]
*** Fulcro handbook
 http://book.fulcrologic.com/
 Most of it is about how om-next itself works. The solutions for a more practical
 om-next are a bit different, and in some ways diverge somewhat from the 'om-next
 way' of doing things.
*** See om-next docs for more useful links
 Such as for graphql, falcor, datomic etc.

 "Om-next by leveraging lisp and immutable values combines the best ideas of
 graphql and falcor in a less cumbersome and more flexible manner."

** Install
To pull in all the tools and libs to build an aum app add

 #+BEGIN_SRC clojure
aum {:git/url "https://github.com/michieljoris/aum.git",
     :sha "577daf362c3f81e08d43f654ef0bbf3ddc93e015"
     :tag "master"},
#+END_SRC

to your dependencies.

To actually build an app it's a good idea to start with a minimal setup, see the
following section.

** Starter app

TODO: add github link to aum-starter-app
There is a repo that's an app using aum libs, but has no minimal content. This
can be used to try out building features/pages.

Clone it and follow the following instructions.

*** Install
Prerequisites:

- mysql
- node
- nvm
- java 1.7 or greater

[[https://clojure.org/guides/getting_started][Install clojure]]

In the starter repo do:

    nvm install
    nvm use

to make sure the proper version of node is used.

And then:

    bin/dev-install

For development also do this:

    Make sure pagora.aum, pagora.clj-utils and pagora.revolt repos are in the same parent dir as this repo.

    So if this repo is in ~/src/aum-starter-app for example, then you should
    also have for instance ~/src/aum  checked out to the most recent master.

TODO-aum: get this working properly!!!
    This is so that tools.deps can resolve the dependencies locally. If you
    want deps from github replace local-deps with git-deps in the bin/backend script


*** Run in production

NOTE: the build task doesn't include deps in aliases into the uberjar. Need to
fix the build task, but for to create an uberjar uncomment the aum-next and
dc-util deps in deps.edn.

Build production jar at dist/app.jar with:

    bin/build

This'll fetch node modules and build the js bundle as well.

Set db user/password/url/db-name, server port and ip, and what logs you would
like by setting the various environment variables and run jar (in dist dir):

    CLJ_ENV=prod DB_USER=test DB_PASSWORD=abc DB_URL="//localhost:3306/" DB_NAME=chinchilla_development QUERY_LOG=true SQL_LOG=true HTTP_LOG=false SERVER_PORT=8081 SERVER_IP=0.0.0.0 NEW_RELIC_LICENSE_KEY="<some newrelic key>" java -javaagent:./newrelic-agent.jar -Dnewrelic.config.file=./newrelic.yml   -Dnewrelic.environment=production -jar dist/aum.jar

or just

    bin/run

Or all in one cmd:

    bin/build-and-run

If tools.deps complains about dirs already existing when cloning repos delete ~/.gitlibs

Clearing classpath cache in ~/.clojure might also help.

See app at http://localhost:8090

Entry point of backend in production is at app.core. It requires web-server.core
which is at the root of the dependency tree and the main method that gets called
from the command line. The main method calls mount/start which starts up all the
stateful namespaces.

*** Run in development

It's practical to run backend and frontend separately. It's rare you need
restart both, but being able to restarting one or the other sometimes is useful.

After bin/install:

    bin/backend

which will get you a clj repl in the terminal.

To set config settings, for example the db, do:

    DB_NAME=chinchilla bin/backend

See config.clj for possible settings and their defaults (replace
hyphens with underscores).

Connect your editor's repl to the nrepl server at port 5700.

In dev mode src-dev is on the classpath so src-dev/clj/user.clj gets loaded.
The sexpr (dev/start) is in that ns so it will be executed which will start the app.

In the repl start/stop/reset the app with (dev/start), (dev/stop), (dev/reset)

To compile the frontend, in another terminal do:

    bin/figwheel

which will get you a cljs repl in your terminal.

See app at localhost:8080

In the nrepl session in your editor run (user/cljs-repl) for a cljs repl

You might have to uncomment the connect-to-cljs-repl defn in
src/dev/cljs/cljs/user.cljs first.

Entry point of frontend is at app.core. Websocket is started here and this is
where om react tree gets mounted, after websocket first open event is received.

Entry point of backend in development is at dev.clj. It has the lifecycle methods. It requires
web-server.core which is at the root of the dependency tree.

NOTE: after building a prod jar, restart both backend and figwheel processes.
This is because the out dir is cleaned before building and the dev versions of both css and js
need to be built again. Or try modify a scss file and a cljs file to
kickstart recompile.

* Build system
TODO: revolt
webpack and foreign-libs
bin scripts
dev-backend: revolt rebel task loads the user namespace
* Core concepts
** It's om-next.
The idea is to stay as close as possible to the original idea of om-next as just
a thin layer on the top of react, but extend some concepts so at the very least
a straightforward crud app can be built really simply and quickly, with simple
tools to facilitate both front and backends development.

Om-next itself is isomorphic, meaning it can ran on either front or backend. Aum
extends om-next, and some of it can be used on both front and backend, but in
general it focuses more on making om-next useful in a practical way. So in the
backend the om-next parser is implemented to query a mysql database, with
security and validation mechanisms.

On the frontend aum implements a parser that in most cases will do the
right thing in denormalizing queries over the app state. And there are mechanism
for dealing with multiple remotes, websockets, error handling, correcting
optimistic updates etc.

Aum has its own thin layers over the reconciler and parser but still uses defui,
om/transact! etc

* Start app
** dev
*** clj
When calling bin/dev-backend the last plugin (rebel) is configured in
resources/revold.edn under the :revolt.plugin/rebel.init-ns to load the clj.user
ns.
In clj.user a restart fn is defined that inits aum, inits a integrant system
with it and then calls (dev/go) on it. This kicks of all the init-key fns in the
various namespaces (db, server etc).
*** cljs
When starting figwheel (by either bin/dev-figwheel or space-m-" in Emacs) the
complier options in dev.cljs.edn get used to produce the js from cljs. The :main
options is set to cljs.user. This is the first file loaded in the frontend by
goog.require and all the dependent files are loaded after that. So cljs.user
should require app.frontend.core. This is enough to get the app going.

* environment
Require pagora.aum.environment in both front and backend. The current evironment
is in the environment var or call functions like is-development? from that
namespace. The default environment is :dev. Start the app with
CLJ_ENV=production/staging/testing to change the environment.
* Config
Config is defined in multimethods like this:

  Config keys need to be assigned scalar values (so no maps or vectors) so we
 can set them in env vars on the command line

#+BEGIN_SRC clojure
(ns app.config)

(defmethod aum/config :common [_]
  {:timbre-log-level :error
   :app-path "app/"})

(defmethod aum/config :dev [_]
  {:timbre-level :info
   :frontend-config-keys [:app-path :timbre-level]})
#+END_SRC

You pass the namespace these methods are defined in to aum (app.config). Any
config defined in :common will be merged with config for the current environment
with the latter overriding keys in the former. This config is then used in aum
and can be requested from aum (aum.core/get-config).

Frontend config works the same way. Keys listed in the backend under
:frontend-config-keys will be sent to the frontend and merged into the frontend
config before the app starts

* Generic save records
When you have a page with records including their joins recursively you might
want to save the whole lot in one hit. aum calculates the actual
modifications, and only sends what's changed to the backend. The backend then
will save these records in the right order, taking into account newly created
records and any dependencies on them and will if anything went wrong with
updating a record return this info per record. It garantuees to leave the db in
a consistent and validated state and returns enough information so the frontend
can correct any optimistically updates to its own app state and make sure it's
stays in sync with the backend.
* Have backend return calculated data

  There are three ways to do this:

** Calculate something over a (sub)query
   Sometimes you want something to be calculated over a query and return not only
   the rows themselves, but also the extra data, such as total count. This is
   particularly tricky if you want to calculate something over a join. You want
   the joined rows, but also some more data over that particular subset of rows
   (joined as they are to the parent record).

   To do this add a :with-meta param key to the params of the query. Set this to a
   single keyword or map or a vector of them. If it's a map it should have at
   least a key :type, but you can then add more params for the calculation if you
   want.

   You can then extend the calc-meta-data multimethod from
   aum.parser.calc-meta-data in the backend which is dispatched on those
   :with-meta keys, or the :type value if it's a map. The method is called after
   the original sql query has been done. The sql-fn called, its args and
   calc-params as passed from the frontend.

   #+BEGIN_SRC clojure
  [{:group [({:user [:id :name]} {:with-meta [:count {:type :calc2 :some :params}]})]}]
  #+END_SRC

  #+BEGIN_SRC clojure
  (defmethod calc-meta-data :count
    [env rows {:keys [sql-fn sql-fn-args return-empty-vector? join-type calculation-params]}]
    ;;Do your calculation here
     )
  #+END_SRC

  One thing to take note of is that the return value for this query will be now of
  the form:

  #+BEGIN_SRC clojure
  {:rows [[:id 1 :name "foo"]] :meta {:count 123}}
  #+END_SRC

  Which means you will have to take this into account when this data arrives at
  your component, and/or when you implement the read method for the join with the
  :with-meta param.

** Define a read key in the backend

  Such as:

  #+BEGIN_SRC clojure
  (defmethod aum/read :calc/count
    [{:keys [user state parser query parser-config] :as env} _
     {:keys [table where] :as params}]
    ;;You can use the query to decide on what to calculate perhaps
    (timbre/info query) ;;=> [:count]
    {:value {:count (count-records env params)}})
  #+END_SRC

  Then add a query to a component:

  #+BEGIN_SRC clojure
  ({:calc/count [:count]} {:table :user
                           :where [:id :< 5]})
  #+END_SRC

  Disadvantage of this method is that you can only use this query as a root query
  or quasi root query. Also you have to possibly duplicate the params of this query in the
  frontend from another query. And this isn't useful for a joined query.

** Redirect a read to a custom-read
  Used search translations. Idea is to set a :custom-read key in the params of a
  query. Backend will use the read method as set to the :custom-read key and pass
  in the rest of params as well.

  Advantage of this is that you can redirect a query for a join to your own read
  method. Where you can then return a calculated value, any rows queried for
  and/or any other data you like.

  #+BEGIN_SRC clojure
  (defmethod aum/read :count-records
    [{:keys [user state parser query parser-config] :as env} _
     {:keys [table where] :as params}]
    {:value (count-records env params)})
  #+END_SRC

  With this query:

  #+BEGIN_SRC clojure
  '({:user-count [:count]} {:custom-read :count-records
                            :table :user
                            :where [:id :< 5]})
  #+END_SRC

* Use datomic pull syntax to query mysql database
Use om-next queries to do crud on any mysql database, where the read can
use one or more joins from and to any table, constrained only by the
(db-)configuration of the parser.
* Security
Aum comes with login and logout fns for both front and backend. However in
production this is disabled and users are directed to the rails app.
The remember token as set by the rails app is used to authenticate the session
similar to how it's done in the rails app. One complication is that because how
sente/websockets work is that to renew the session and any attached remember
token the connection has to be renewed.
* Internationalization
There is a common.i18n.cljc namespace which provides the translate fn which
takes the current locale and a key.
* Websockets
* Write validation
A generic sql query fn that garantuees validation (doesn't work if not
implemented) of the query with hooks for pre processing the params of the query
and post processing of the result of the query.

** Sql validation
 Every call to the sql fn in the database.query ns by default is validated by
 calling the aum validate-sql-fn multimethod. This dispatches on sql fn
 keyword. For all mutating sql queries as defined in the aum.database.queries
 ns the proper validation fn is retrieved using security/get-validation-fun.
 This can be set in the database.config but if not the multimethod
 aum.database.validate.core/validate multimethod is called, dispatching on
 role of the user, method (sql fn keyword) and table.

Idea is that for every hugsql fn added you will have to write a validate-sql-fun
 method otherwise it will just throw an exception when its called through
 database.query/sql. You can write an empty method, and then no validation is
 done. You can do validation right there and then, or you can retrieve an
 appropriate validation fn by calling security/get-validation-fun. You will
 probably wil have to add a fn to database.config or add an appropriate
 aum.database.validate.core/validate method. Otherwise, again, an exception is
 thrown by default.
** Sql process-params, process-result
In essence all the database.query/sql fn does is first call
aum-process-params, then process-params on the params, call validate-sql then
call the actual hugsql fn and then call aum-process-result and then
process-params on the result.

aum-process-params does some built-in params processing, same for
aum-process-result. Custom versions of these fns will be used if set in the
sql prop of env.

process-params does nothing by default, process-result just returns result as
passed in.

aum.database.queries ns is used to resolve the hugsql fn

It's also possible to add an extra hugsql ns for resolving the sql fn.
(aum-)process-params, (aum-)process-result and validate-sql-fun are all
multimethods so you can add methods to deal with any extra hugsql fns.

process-params (and process-result) is handy for adding hooks. For instance for
the event-store. For more detail see also doc string of database.query/sql fn.
* Frontend
** make-cmp and om-data
** Use pages to organize your ui
There are some basic fns for this. See app.pages for how to add a page.
** Client only keys
Any key with a namespace that starts with :client will never be sent to the
backend. The value for any key with the namespace :client will be looked up in
the root of app state.
** Validation of form values
When doing a save of a record on a particular page aum looks in the app
config for that page a validation function for every prop of the record. If any
prop is not 'valid' it's added to the client/invalidated-fields map of the state
for that page (under the table key for that record). This can be queried for in
the relevant component and used to set any ui flags and/or messages for that
field.

TODO:
Currently this happens when a record gets saved, but it's possible to add a
mutation that does this on demand, for instance on onBlur..
** Syncing of front and backend
All records have as their meta data something like this:
#+BEGIN_SRC clojure
  {:record {:id 1 :type :foo :name "bar"} ;;record as it came from the servr
   :uuids [] ;;history keeping
   :prev-uuid nil}
#+END_SRC
The meta record map is nil unless something has been modified in the record
itself. The various uuid keys are used for undo/redo functionality. They are
references to a particular state in the history of states for the app as kept by
om-next.

Reverting a record is as easy as replacing with its meta record. Calculating
what has changed to a record for purposes of sending modification to the backend
is doing a diff. And to decide whether its 'dirty' aum in essence just
does a comparison.

It's possible for example to reset just the one prop of a record as a result of
clicking a 'reset' button in the component for that field. The original value
can always be fetched from the meta record.
** Generic recursive read with hooks
*** Intro
**** Combining queries
In om-next the root query is composed of sub queries recursively as they're
pulled from components. However not every component necessarily represents a
database row, or sequence of rows of a database table. Sometimes a component is
just a grouping of other components. These components still need their own
queries. A natural way of doing that is to use placeholder keys. Both front and
backend parsers skip over these keys and just keep parsing and trying to return
values for deeper lying keys instead. In the case of the backend if a key is not
a table as set in the database config it will ignore it. In the frontend the
parser just grabs the value of the key if it exists in the app state and keep
parsing.
**** Finetuning parser result
In om-next for every render the complete root query is applied over the
app-state (basically the same as the om-next function db->tree). This works fine
for a small and simple app, however as an app gets more complicated you would
like to have a bit more control of what gets returned for a key and/or if a key
is included in any remote query. A standard om-next parser only implements
reading the root query keys. In other words, it's not recursive. The aum
parser recursively tries to interprete a query and will call any hooks for keys
if they exist. So at any time during the parsing of a query you can insert your
own code for resolving values and any remote. If you want to keep resolving any
deeper lying queries you can call the supplied db->tree passed in the env
(similar to how you received the parser in standard om-next).

Standard om-next has something like dynamic queries. This extends this idea by
letting you respond to app-state changes and changing what gets returned for any
key anywhere in a query for both value and any remote. For instance you can set
the selected-id in app state to 123 and in the query for your record in your
'selected-item' component adding the right parameters to the query that goes to
the backend. This should return the selected item once it's been fetched, but if
you want you could customize that value as well, for example because you want to
calculate a client side prop and add it to the value. Requesting and returning
batches of items can be implemented similarly.

*** Adding hooks for keys and joins in the root query for returning values and building remote query
**** Principles
   The standard read method of aum is db->tree of om-next. This will return a
   tree of data by applying the root query over the app-state. The stock om-next
   db->tree fn has been extended in the following ways:

   1. It's possible to define read methods for any key anywhere in the query. If
      you do you can then return anything you want for that key. You will get in
      the env the ast for the om-next expression (join or prop), the query if it's
      a join, context-data and (app-)state. Context data is the data relevant for
      the prop or join, which depends on where in the root query the key for the
      join or prop is. For instance the default way to resolve a prop is just to do
      (get context-data key). Default way to resolve a join is db->tree on the
      query and context-data (see aum.reconciler.parser.key.route and the read
      method for [:value :route/*]).

   2. The db->tree fn has been modified so that it instead of returning data it'll
      return the query again, but 'sparsified' when :sparsify-query? flag is set.
      By default if any data is found that part of the query is elided. But again
      you can add read methods to determine yourself if and what should be included
      for any key in the root query. In standard om you need to return a (possibly
      modified) ast. For these aum read methods to work you return a (modified)
      query instead. Whatever you return will be included in the remote query. If
      you want to process and modify the ast you can you just do a (om/ast->query
      ast) when you're done editing it. You can also return true which will then
      result in the query being parsed further the standard db->tree way. Note that
      currently if the key is a prop only the truthiness of the return value is
      used. If truthy the return key is included, otherwise it isn't. Return the
      full query in case of a join. So for a read method for [:aum :foo] you
      return {:foo [:some :query]}. If query had params you can add them again,
      possibly modified.

   3. Read method is dispatched on key, or on [target key]. Second one takes
      preference over first. In the first instance you need to return a map such as
      {:value :some-value :aum {:some-key [:some :query]}} similar to standard
      om-next read methods.

**** Examples
***** VALUE example
   The method (note the :value in the dispatch vector):

   #+BEGIN_SRC clojure
   (defmethod aum/read [:value :bar] [{:keys [query context-data] :as env} key params] ...)
   #+END_SRC

   for a app state structure like this:

   #+BEGIN_SRC clojure
   {:foo {:bar {:k1 1 :k2 2}}}
   #+END_SRC

   and a root query of:

   #+BEGIN_SRC clojure
   [{:foo [{:bar [:k1 :k2 :k3]}]}]
   #+END_SRC

   receives env like this:

   #+BEGIN_SRC clojure
   {:query [:k1 :2]
    :context-data {:k1 1 :k2 2}
    :ast {:type :join, :dispatch-key :bar, :key :bar, :query [:k1 :k2],
          :children [{:type :prop, :dispatch-key :k1, :key :k1} {:type :prop, :dispatch-key :k2, :key :k2}]}
    ...
   }
   #+END_SRC

   and should return for example this:

   #+BEGIN_SRC clojure
   {:k1 1 :k2 2}
   #+END_SRC

***** REMOTE example
   The method (note the :aum in the dispatch vector):

   #+BEGIN_SRC clojure
   (defmethod aum/read [:aum :bar] [{:keys [query context-data] :as env} key params] ...)
   #+END_SRC

   for a app state structure like this:

   #+BEGIN_SRC clojure
   {:foo {:bar {:k1 1 :k2 2}}}
   #+END_SRC

   and a root query of:

   #+BEGIN_SRC clojure
   [{:foo [{:bar [:k1 :k2 :k3]}]}]
   #+END_SRC

   receives env like this:

   #+BEGIN_SRC clojure
   {:query [:k1 :k2 :k3]
    :context-data {:k1 1 :k2 2}
    :ast {:type :join, :dispatch-key :bar, :key :bar, :query [:k1 :k2],
          :children [{:type :prop, :dispatch-key :k1, :key :k1} {:type :prop, :dispatch-key :k2, :key :k2}]}
    ...
   }
   #+END_SRC

   and should return for example this:

   #+BEGIN_SRC clojure
   {:bar [:k3]}
   #+END_SRC

   to create a remote query like this:

   #+BEGIN_SRC clojure
   [{:foo [{:bar [:k3]}]}]
   #+END_SRC

   If you want to keep the params (or add, or modify) return something like this:

   #+BEGIN_SRC clojure
   (cond-> {:bar [:k3]}
     (some? params (list params)
   #+END_SRC

***** Routing

 Sometimes you would like to only load (send with the remote) a particular
 segment of a root query, for instance based on route of page that the user
 selected to display. By setting the selected page in app state you can (by using
 key inheritance and multimethods) only return a remote for a key that matches
 that page:

 #+BEGIN_SRC clojure
   (defmethod aum/read [:value :page/*]
     [{:keys [state default-remote context-data query db->tree] :as env} page params]
     (let [current-page (:app/page @state)]
       (when (= current-page page)
         (db->tree env {:query query
                        :data  context-data
                        :refs  @state}))))

   (defmethod aum/read [:remote :page/*]
     [{:keys [state] :as env} page params]
     (let [current-page (:app/page @state)]
       (= current-page page)))

     (doseq [page [:page/some-page :page/some-other-page]]
       (aum/derive-om-query-key! page :page/*))
 #+END_SRC

This implements basic 'routing'.

This is
***** Pagination
Set the query for the items you want to display paginated (or with infinite
scroll) in the relevant component. This will by default fetch all available
records (or as many as the server is willing to send in one batch). This is not
what we want so we add a hook for the query for that component. In that query we
add the proper params (such as limit, offset etc). These values will (should)
have been set in app state with a mutation (triggered by a scroll or click of
pagination button). Now only the records for a particular page are fetched. If
we are paginating this is enough. If we are scrolling we need to 'cache' the
list of idents already in place for our key from a previous query. Then on read
of that key we need to prefix the cached list of idents to the actual list of
idents received from the backend.
***** Autocomplete
Add a hook for the key for the autocomplete component. Return nil for any remote
and it will not be added to the root remote query Once a search term is set in
app state we adjust the query for the autocomplete component and add the right
params (eg. {:where [:name :like "%my search%"]}). This will make data avaliable
for the autocomplete component to display in its dropdown. This search term in
app state will have to cleared when navigating away from the page otherwise it
will be acted on again when returning to the page with the autocomplete.
**** Notes
- If you set ignore-hooks? to true db->tree will function as the standard om-next
db->tree, but by setting :sparsify-query? to true you can still also calculate
the remote query.

- In aum.reconciler.parser.denormalize there's a comment block where you can
play around with db->tree. There's also the try-frontend-read ns.

- To see the whole process in all its glory set timbre-level to :debug in
app.config.cljs and set the chrome dev console to verbose output.

_ For read methods the parser is not available in the env, but db->tree is.

Use of that is simple:

#+BEGIN_SRC clojure
     (db->tree env {:query query ;;Apply this query
                    :data  data ;;to this data
                    :refs  app-data ;;looking up idents (refs) here.
                    :sparsify-query? false ;;Return the data, not a sparsified query
                    :ignore-hooks? false
})
#+END_SRC


** Security
There's login/logout methods in app/security.cljc. Disabled in production.
** Garbage collection
There is currently no garbage collecting implemented. As with any garbage
collection the criteria for this are rather app and platform specific. But in
principle you will only have to delete any data from app state and if the ui
gets in a state where it requires that data it will just be added to any remote
query again.

A history of all app-state is kept, this is limited to 100 by default. This
could be reduced. On page change you could just wipe any idents referred to
by that page.
** Internationalization
There is a common.i18n.cljc namespace which provides the translate fn which
takes the current locale as passed into components as a computed property and a
key.
** Post remote
Sometimes you would like to a take some extra action _after_ a remote mutation has
finished and the data has been returned. For every mutation method you can
define a same name post-remote method. This is called with the value as returned
from the backend. Here you can do error handling for instance or 'clean up' the
response before it get merged with app state.
** Pre-merge hooks
These hooks allow you to take action before _any_ value gets merged with
app-state, including responses to read queries.
** Merging pushed data
Backend can use websockets for resolving queries from the frontend, but this
means it's also possible to 'push' data. The frontend can  respond to this and
merge this as any regular response to a query. This is useful to keep instances
of the app in sync, but also to show notifications, or to push a response of a
query in an async manner. It can be sent to the frontend if and whenever the
required data is available.
** Generic undo/redo/revert.
Every mutation on a record adjust some metadata on the record that enables
undo/redo/revert for that record. This also includes any data joined to that
record, they will also get undone/redone/reverted.
** Run backend in frontend (for testing for example)
It is possible to run the whole backend in the frontend where the mysql database
is 'mocked' in the frontend. This is ideal for writing integration tests
covering the whole stack
** Test runner
Standalone client-side om-next test-runner app to be used with the
alternative test macros that add and remove tests to the lists of tests. Several
ways to display diffs. Rerun test on click. Use snapshots for any test instead
of writing the required result into the test. Helpers to click and compare html
output for acceptance ui tests. Replay/rewind/step through (ui) tests by using
pause macro.
** Snapshot testing
There are facilities to create a test by putting it together step by step and
instead inserting expected results take snapshots and use them instead. This is
particularly handy for testing states of the ui. It's also then possible to step
through the test in the test runner. If any intermediate snapshot fails the test
but (because we updated the code for example) is what we do expect we can update
the snapshot by clicking a button.
** Whole stack testing
By combining test runner, snapshot testing and running backend in frontend it's
possible to do whole stack testing.
** Inspector
Search, filter and drill into app state.
** Dev-cards
    Switch to dev cards page from app itself.
* Testing
First install nvm (node version manager).

Then

    nvm install
    nvm use
    npm install
    npm install -g karma-cli

TODO

* Debug production/staging

It's possible to set some flags in local storage to get some output in console
etc:

Set log level:

    :timbre-level :info

Click on AUM logo and some debug buttons will show up:

    :debug-drawer true

Show what query is sent and what is returned:

    :send true

Show item id in lists:

    :display-item-id true

Show debug buttons in page bar:

    :debug-buttons true

In boot-scripts there's tail.boot to inspect logstash output:

    boot boot-scripts/tail.boot -h

Options:
  -h, --help        Print this help info.
  -f, --follow      follow
  -s, --start VAL   VAL sets start (line number or time (hh:mm) such as "11:10").
  -n, --length VAL  VAL sets number of lines or length of time such as "10h", "5m" "50s" If start is given then last so many lines or within last so much time.
  -t, --http-log    print http output lines
  -i, --timestamp   print timestamps
  -r, --regex VAL   VAL sets regex to filter lines.
  -l, --level VAL   VAL sets level to filter such as info or error.
* Misc
** Querying other sources than a mysql database
*** Using more than one remote in the frontend
Example: lawcat
*** Returning data fetched from another source
Example: tent
*** Integrating pathom
** Trying queries
In the dev source folder there are namespaces to try out various queries:
*** try-om-query
You can call the backend parser with any om-next query. These are resolved
against the database as defined in app.config and using database.config as
defined for the whole app.

There is a second version where you can build your own parser environment and
your own parser with that again.
*** Try sql query
To try out any sql query. Make sure to define process-params, validate-sql-fn
and process-result methods, and the equivalent sql fun in build-sql if you want
it to be used in mock mode or tests.
*** Try/test frontend parser.
Frontend parser is a cljc file so you can eval this in a clojure repl. You can
test here what the parser returns for queries for the nil and various remote
targets, which is much harder to test/inspect if you have to use the ui to pass
queries to the parser.
** Fixtures per test
    It's possible to set up a context for one more tests to run in. Inside the
    macro call `in-context` you'll have access to tu/*env* which will be set
    properly according to the context you're in. The *env* has db-conn which you
    can use directly or you can use the a parser or aum.database.query/sql and
    pass in *env*. For your convenience two more dynamic variables, tu/*parser*
    and tu/*state* are bound while 'in-context' using the parser-config and
    db-config passed in when creating a context using tu/make-context.

#+BEGIN_SRC clojure
  (require
   '[aum.app-config :refer [config]]
   '[clojure.test :refer [deftest is]]
   '[aum.test.util :as tu :refer [debug-tests unload-all-tests unmap-all-interns in-context truthy?
                                    make-context query]]
   )


  ;;This will create just the one table, foos, with just one row.
  (def fixtures {:foos {:rows [{:id 1 :title "bar"}]
                        :options {:id-primary-key? true}
                        :schema {:id :int :title :text
                                 :updated-at :date-time :created-at :date-time}
                        }})

  (def my-db-config
    {:root true
     ;;by default you can refer to a table by its singular name (the end s is
     ;;removed from the table-name).
     ;; :table-name :foo :columns
     (keys (get-in fixtures [:foos :schema]))
     ;; :joins {:bar {:t1-foreign-key :bla-id}}
     :read {:role {"super-admin" {:blacklist []}}}
     ;;NOTE: For update, create, delete mutations you'll might have to create the
     ;;appropriate validations as well.
     :update {:role {"super-admin" {:blacklist [:id :updated-at :created-at :creator-id]}}}
     :create {:role {"super-admin" {:blacklist [:id :updated-at :created-at]}}}}
    )

  (def context-foo
    (make-context
     {:db-config {:foo my-db-config}
      ;;Or use config from your app:
      ;;:db-config (select-keys database.config/db-config [:user])
      :parser-config (merge (config) {:allow-root true :print-exceptions true
                                      :sql-log true :query-log true
                                      :event-store-disabled true})
      :fixtures fixtures}))

  (def user {:id 1 :some-user "a-user" :role "super-admin" :group-id 10 :subgroup-ids [-1]})

  (in-context context-foo
    (tu/*parser* (assoc tu/*env*
                        :user user)
                 [{:foo [:id]}]))

#+END_SRC

* TODO: Snippets

#### Server parser

    (def parser-env (aum/parser-env {:parser-config {
                                        :normalize true}
                                    :db-conn some-db-conn}))

    (def parser (aum/parser {:parser-env parser-env}))

    (def state (atom nil))  ;;will contain table if :normalize is true, and/or error data

    (def user {:id 1 :name "foo"}) ;;or nil.

    (aum/parser {:state state :user user} om-next-query)

For more options to pass to aum/parser-env see the aum.parser namespace.

This parser will translate the om-next-query into a sql query and return the
result with the table data in the state atom if :normalize is true.

By default the user in env is checked to be truthy. If falsey {:value
:not-authorized} is returned by the aum parser. To bypass this use the read
and mutate multimethods in aum.parser-read and blby.parser.mutate namespaces:

Require

    [aum.parser.read :refer [read]]
    [aum.parser.mutate :refer [mutate]]

And define parser thusly:

    (def parser (aum/parser {:parser-env parser-env
                               :read read
                               :mutate mutate}))

Or use your own mutate and/or read fns. The env will be populated with the keys
from the parser-env, as long as they are not overwritten by om-next env keys.
Optionally, the schema of the db will be under the :schema key

If using aum read/mutate fns parser will still use the user map to check for
permissions and validations in db-config, and will still substitue namespaced
keywords in queries with values from the user map if possible.

By default the aum parser will inspect the schema of the database given in the
db-conn and infer and check table and column names, and table joins. These can
also be explicitly described in db-config (TODO for table names and columns I think).

#### Client reconciler and parser

TODO: Add docs..

#### Test runner

TODO: Add docs..

### Result format

    {:value {...}
     :status :ok/:error
     :table-data {...}
     :original-table-data {...}}

- :status
can be :ok or :error. In the case of error one of the keys queried for
threw an error. Value of the key will be the error data.

- :table-data
will always have data as stored in the database, in other words it's
a subset of data in the database, this can be data as linked in to in a
(normalized) query result, data as queried for in save-record post-save

- :original-table-data
server table data after a failed mutation, potentially useful to repair frontend version of data

- :value
is the result of the query/mutation

In the case of a mutation :value will have this format:

    {mutation-symbol {:error {:stacktrace :not-returned
                            :context {...}
                            :message "..." }
                    :keys [..] }
                    :tempids [..]}

Any of tempids, keys and error is optional.

keys is a hint of the server for rerender, for affected table data.

In the case of error, for a mutation, the error message will the in the map for
the mutation symbol. For an error in reading a key, the error

* Translations

Keys given to common.i18n/translate can be a string or keyword. When capitalized
translation will be capitalized as well. These can, but don't need to be
prefixed with admin/. When looking up a key, key will be prefixed with admin/ if it's not
already. Keyword keys will be changed into strings (without leading keyword colon).

Examples:

    :foo lookup keyword in src code will require admin/foo key in translation database
    :admin/foo => admin/foo
    foo => admin/foo
    foo bar box => admin/foo bar box

The admin/ prefix allowes to fetch admin relevant translations only.

Set :mark-untranslated-keys to true in local storage and/or app.config.clj(s) to
show untranslated keys as the full key in brackets.


* Integrations

** Bugsnag
See integrations.clj and integrations.cljs.

Bugsnag is added to both front and backend. In app/config.clj both keys are set.
Bugsnag ring wrapper is added in webserver.handler.clj. See integrations.clj for
example of calling bugsnag-notify directly. See integrations.cljs for wrapper
fns to call bugsnag notify, breadcrumb and refresh in frontend.

To test bugsnag in development add valid keys to :dev config in app/config.clj.
If the key for the frontend is nil bugsnag script is not added to admin.html

** New relic

To test new relic in development:

Copy newrelic-agent.jar to repo dir, this uses jar version as specified in build.boot:

    boot copy-newrelic-jar

    NEW_RELIC_LICENSE_KEY="<some newrelic key>" bin/boot-with-jvm-options

See .boot-jvm-options for actual jvm options used. They include among other
options the -javaagent option. You should see some data popup in your newrelic.

To run new relic in production:

boot build task includes the copy-newrelic-jar task, so newrelic-agent.jar
should be in the projects root dir. Incantation below to run production jar
includes new relic api key env variable and jvm options to run new relic agent.
Logging is set to the cwd, as set in new relic config file at ./newrelic.yml.

If new relic license key env variable is not set new relic agent is not loaded.

** Logstash

Set logstash host, port, level and enabled in app.config.clj. Alternatively set
env variables logstash_host, logstash_port, logstash_level and logstash_enabled
before starting aum. See dev.clj for trying logstash in development.


* HOW TO

### Modify url path of app
- End path with slash
- Modify path var at top of build.boot
- Modify path var at top of app/config.clj
- Move content of resources/<path> and src/cljs/<path> to the new path.
- Edit resources/<new path>/admin.html and set new path for css and js files

### Cursive

### Tips
See for graph of dependencies ns-hierarchy.png. Produced with medusa. Might be outdated.

Enable/disable various debugging settings in cljs/app/config.cljs. Very handy to
work out what om-next is actually doing.

### Mobile debugging:

- Set vorlon-script to true in config.clj or set env var.
- Install vorlon: http://vorlonjs.com/
- Run vorlon on commandline
- Open mobile device at your lan interface:port
- Open vorlorn dashboard at localhost:1337

### Add npm modules

- Add to package.json
- Import package in index.js, set a global to imports
- Create index.bundle.js by running npx webpack
- Create externs file or add externs to foreign-libs.externs.ext.js
- Edit resources/revolt.edn (and/or main.cljs.edn for figwheel):
- Add any new externs file to the externs keys
- Add entries for the exported packages to foreign-libs under the
- foreign-libs/index.bundle.js entry:
- -> The global created in index.js should be added to the global-exports subkey
  where the js global var name can be referred to by a clojure symbol ns
- -> Add that symbol ns to to the provides key as a string.

### Analyze size of webpack bundle

    npx webpack --config webpack.prod.js --json > stats.json

Upload stat.json to https://chrisbateman.github.io/webpack-visualizer/

Or:

    bin/analyze-webpackold-app-readme


* superaccounts
Groups get a flag whether they're a supergroup or not.
A group admin gets the role of supergroup-admin if his group has the supergroup
flag set. This is used for validation/permissions purposes
front and back end, and also for ui concerns/behaviour in front end.
At the moment a AUM user (group 10) gets automatically super-admin role, and
based on that allowable props to read/update/create, and scope for read are set and
validations performed.
A group admin has different crud props and validations applied to him. Scope is
for instance [:where [:group_id := u/group-id]]. Where u/group-id is the
group-id of the current user, the group admin. Frontend asks for the same data,
however only gets groups, or dossier types, or users belonging to the current
user's group.
So everything is in place for supergroup-admins as well. We just need to
determine whether a group-admin is a supergroup-admin (we look at the supergroup
flag on the group he's from), and what other groups he's got access to (any
group created by a supergroup-admin automatically get their group-id set the
supergroup's id).

Before we do anything in the parser we add the current user to the environment.
Here we add for instance the role prop to a user. Here is also where I fetch all
the subgroup ids of the user's group, and add that to the user's prop if he's a
group-admin.

Then for supergroup-admin I adjust the scope to [:where [:group-id :in
:u/subgroup-ids]] for the various tables like dossier types, users, etc.

And that's basically it. If you look at a supergroup's data in the ui you'll see
a list of subgroups. If you look at a subgroup you see what supergroup it
belongs to.

If a group-admin of a supergroup logs in they will see what service desk sees,
and can do what they do, limited to the supergroup and the subgroups.

It becomes then a matter of finetuning permissions and validations. And making
sure everything is robust enough.

This does not affect AUM app at all. It works as it did before. You just give a
supergroup-admin to administer some more groups instead of having to go through
AUM's service desk.

* backend response format
{:value {...}
 :status :ok/:error
 :table-data {...}
 :original-table-data {...}}

:status
can be :ok or :error. In the case of error one of the keys queried for
threw an error. Value of the key will be the error data.

:table-data
will always have data as stored in the database, in other words it's
a subset of data in the database, this can be data as linked in to in a
(normalized) query result, data as queried for in save-record post-save

:original-table-data
server table data after a failed mutation, potentially useful to repair frontend version of data

:value
is whatever the query/mutation returned in the backend

In the case of a mutation :value will have this format:
{mutation-symbol {:error {:stacktrace :not-returned
                          :context {...}
                          :message "..." }
                 :keys [..]}
                 :tempids [..]}

Any of tempids, keys and error is optional.

keys is a hint of the server for rerender, for affected table data.

In the case of error, for a mutation, the error message will the in the map for
the mutation symbol. For an error in reading a key, the error will be under the
key. However reading is pretty forgiving in general.

If there's an error in either reading or mutating for any key status will set to :error

* post-remote
Every mutation can return in the response map, besides entries for :action and
any remote keys, also an entry for :post-remote. This should be a function and
it will be called with the result of the specific mutation on the backend. Usually this
will be just a map with possibly :keys and :tempids entries. However in case of
an error backend can add (which it usually does) an entry for :error. This is
the place to do any cleanup or post remote action.

The post-remote function should return a map looking like:

{:keys keys ;;hints for om-next to rerender certain components
 :value value ;;You can any map here you want to, gets merged with app-state
 :table-data ;;gets merged-with app-state
 :records-to-process [] ;;a vector of maps with instructions on processing individual records
}

The result of the post remote gets deep merged with the complete response from the server
for the complete query.

The records-to-process vector doesn't get processed till _after_ value and
table-data are merged with app-state

records-to-process maps should look like this:

{:table :some-table :id <some-record-id>
 :reset-history? <boolean> ;;wipes history in meta of record (:next-uuid :uuid :uuid-trail)
 :synced? <boolean> ;;whether to wipe :record key in meta of record
 :dissoc-key :some-key ;;dissoc's key from record
 :recalc-is-dirty? <boolean> ;;whether to recalcuate is dirty for the record
}

Keys returned from mutations are all queued for rerender.

TODO:
- Just use one key to merge with app-state, not value AND table-data
- The records-to-process is a leftover from before there was post-remote, this
  functionality should be pulled out of the reconciler and just made into util
  fns, to be called and used in the post-remote fn for the mutation.

NOTE:
Reconciler does some nifty thing where it reapplies user edits to records after
response is merged. Since response and the post remote could be clobbering these
edits we take note of them, and then reapply them when all merging is done.

* run tests in frontend in the app itself on src change:
In dev mode you can run frontend tests on change of src. In debug drawer there's
also a button to run the tests. You can turn this running of tests on src change
on and off with a checkbox in the debug drawer.
App bar will be red if tests don't pass.



* shadow-translations
  The query for the translation form contains a key :translation (join to shadow translation).
  This join has {:set-params :selected-group} as params. See app-state. In
  effect the joins params are altered so that the shadow-translation for the group is queried for.
  Problem is to only sent this query to the backend if we haven't loaded the
  shadow translation for the group yet for the root translation.

  In reconciler.core we've added a pre-merge hook which picks up any
 translations just loaded, and if they have a translation prop (so we queried
 for shadow translation for the translation) we add the shadow translation to
 the :client/shadow-translation prop of the translation.
 If the :translation prop exists but it's not populated (empty vector) we create
 a new client side shadow translation and add that instead to the
 :client/shadow-translations prop.

In app-state the read hook :selected-remote-keys fn is set. Here we override the
default aum read for a selected item. As normal, we add a key to the remote
for the translation if it doesn't exist in the translation we have already. But
we only send the :translation key (the shadow translation) to the remote if we
haven't got a shadow translation yet for the current group.

For local reading purposes we also define the :update-selected-value hook where
we denormalize the ;client/shadow-translations prop.

Then in the template we pick the shadow translation for the current group. Or
none if no group is selected.

This way we can freely switch between translations and groups and still only do
minimal querying of the backend.

Since both the app and the translation page can get translations, including
their shadow translations we have a pre-merge-hook in reconciler.core where we
gather up any (shadow) translation joins and add them to a
:client/shadow-translations key on the root translation. Normally this only has
the translations for the user's group. However when we edit the shadow
translations for various groups (as super-admin or supergroup-admin) this vector
will contain more than one shadow translation (for the various groups). When we
build the translation-map in reconciler.parser.read we pick the right one by
group. Same when we render the translation page. If we have a group selected and
we need to know what shadow translation we should display we pick the right one
from the shadow translations (as parsed and read into props of the component
because we got a client only query :client/shadow-translations on the list and
form queries).

* icons
Icon classes like icon-cached, icon-undo, icon-redo etc are  defined in
mui-icons.css

This is a generated file on
https://icomoon.io/app/#/select

Click "Import icons" and select icomoon.svg in the
aum/resources/admin_new/fonts directory. This adds currently used icons in the
app to the selectable icons. Select all imported icons.

Select any extra icons you want and then click "Generate Font". It exports a zip
file which includes currently used icons in app, plus any other you've addded..

Put the files in the fonts directory in aum/resources/admin_new/fonts,
replacing the files that are already there.

Replace the contents of mui-icons.css with the css in style.css.

* config
- when running bin/dev or boot dev in the dev-task there is
   (environ :env {:clj-env "dev"})
  This sets an env var which is picked up in app.environment. app.environment
  defines a fn that returns current environment. Which is called in app.config
  to decide on which config (dev-config, prod-config, staging-config or
  test-config) is used to build app.config/config var. The various configs have
  for ease of use a :clj-env key naming for what environment the config is for.

  As explained in the app.config ns itself, any env variable set on command line
  or set in profile.boot (using environ lib) will override any hardcoded setting
  in app.config. For this reason any keys in any config map will have to be
  scalar values. Because bash env vars are scalar values (numbers, strings etc).

  Of course when config map actually gets defined it's possible to build up
  submaps to be used in the app.

  When starting up a jar (eg bin/test-prod-jar) you will need to set the clj-env
  environment variable. There's a (environ :env {:clj-env "prod"}) in the build
  task, but this has only effect on the build. Not the running of the program
  (when running the jar).

  Require app.config if you need settings [app.config :refer [config]]. However
  in om parser read and mutate methods the config is part of the env param
  passed in as :parser-config. Better to use that so it can be more easily
  mocked in tests.

  At top of app.config ns there is env-keys defined. This is a set of all
  settings that can be overridden/set on the commandline or profile.boot.

* (sql) validation
 Every call to the sql fn in the database.query ns by default is validated by
 calling the aum validate-sql-fn multimethod. This dispatches on sql fn
 keyword. For all mutating sql queries as defined in the aum.database.queries
 ns the proper validation fn is retrieved using security/get-validation-fun.
 This can be set in the database.config but if not the multimethod
 aum.database.validate.core/validate multimethod is called, dispatching on
 role of the user, method (sql fn keyword) and table.

Idea is that for every hugsql fn added you will have to write a validate-sql-fun
 method otherwise it will just throw an exception when its called through
 database.query/sql. You can write an empty method, and then no validation is
 done. You can do validation right there and then, or you can retrieve an
 appropriate validation fn by calling security/get-validation-fun. You will
 probably wil have to add a fn to database.config or add an appropriate
 aum.database.validate.core/validate method. Otherwise, again, an exception is
 thrown by default.
* sql process-params, process-result
In essence all the database.query/sql fn does is first call
aum-process-params, then process-params on the params, call validate-sql then
call the actual hugsql fn and then call aum-process-result and then
process-params on the result.

aum-process-params does some built-in params processing, same for
aum-process-result. Custom versions of these fns will be used if set in the
sql prop of env.

process-params does nothing by default, process-result just returns result as
passed in.

aum.database.queries ns is used to resolve the hugsql fn

It's also possible to add an extra hugsql ns for resolving the sql fn.
(aum-)process-params, (aum-)process-result and validate-sql-fun are all
multimethods so you can add methods to deal with any extra hugsql fns.

process-params (and process-result) is handy for adding hooks. For instance for
the event-store. For more detail see also doc string of database.query/sql fn.
* Read permissions and create/update/delete permissions, and validations of om-queries
These are set in database.config namespace.
* frontend testing
- Run
    npm install
in aum dir
- Run
   npm install -g karma-cli

Browser in memory sql options:
https://github.com/kripken/sql.js
https://github.com/agershun/alasql/wiki/Getting%20started

parser.core is now a cljc file, including all its deps
* Deciding on selected group
The app can be in a state where a group is 'selected'. In this state certain
pages (like users, translations) will manage records only from/for the selected
group. Some pages are immuun ie, they behave the same regardless of selected
group, like groups page itself, or job offers, or support questions. Other pages
only can only edit records of a particular group, like dossier types, pdf
options.

By default a selected group is the current user's group. But it can also be
set/derived from local/session storage (or from any state in the url
(unimplemented as of 7/18)). The app can be in a state of 'all groups' by
setting selected group-id to -1 or nil.

Complication is that on refresh, while we're logged in, we don't know what the
current user's group is since we don't have that info yet. One
massive query goes to the backend asking for the current user's data, and any other
data required for the current page. Solution for this is not to ask for any
specific group-id number, but for a property on the current user, so for
u/group-id in this case.

The backend resolves what user is actually making the massive initial query
before parsing the actual query itself. (This enables role based access, scoping
etc) The user is passed into the query parser, and any params that are
namespaced keywords are resolved against the user's map first.

We need to weave this variable group-id into the queries that go to the backend.
We're not using om-next dynamic queries at all, but instead give parameters to
query keys that are picked by the cljs query parser. These parameters are like
{:params :selected-group} for instance. The parser goes and looks for the
:selected-group entry in the :params value of the config for the current page.
This can be a map, in which case this is used as the params map for the key in
the query, or a fn. This fn is called with app-state and the result is used as
the params for query key.

All this is not very standardized actually, and there's parallel mechanisms
currently. We have one for batch queries: :batch-params and one for single
record queries: :params. Under a table entry for a page-config we have similar
entries for deciding on what remote keys to send (:selected-remote-keys and :batch-remote-keys).

In any case, initial group-id is set in reconciler.app-state, per page, where
it's usually set to whatever is :selected-group in storage, or if that's
desirable, u/group-id, meaning the user's group-id.

* Trying queries
In the dev source folder there are namespaces to try out various queries:
** try-om-query
You can call the backend parser with any om-next query. These are resolved
against the database as defined in app.config and using database.config as
defined for the whole app.

There is a second version where you can build your own parser environment and
your own parser with that again.
** Try sql query
To try out any sql query. Make sure to define process-params, validate-sql-fn
and process-result methods, and the equivalent sql fun in build-sql if you want
it to be used in mock mode or tests.
** Try/test frontend parser.
Frontend parser is a cljc file so you can eval this in a clojure repl. You can
test here what the parser returns for queries for the nil and various remote
targets, which is much harder to test/inspect if you have to use the ui to pass
queries to the parser.


* Start aum with different ports and db:
DB_NAME=chin_dev_minimal SERVER_PORT=9080 NREPL_PORT=38401 RELOAD_PORT=46501 bin/dev
* pathopt
  https://awkay.github.io/om-tutorial/#!/om_tutorial.I_Path_Optimization
  Path Optimization
As your UI grows you may see warnings in the Javascript Console about slowness.
If you do, you can leverage path optimization to minimize the amount of work the
parser has to do in order to update a sub-portion of the UI.

If you pass :pathopt true to the reconciler, then when re-rendering a component
that has an Ident Om will attempt to run the query starting from that component
(using it's Ident as the root of the query). If your parser returns a result, it
will use it. If your parser returns nil then it will focus the root query to
that component and run it from root.

When it attempts this kind of read it will call your read function with
:query-root set to the ident of the component that is needing re-render, and you
will need to follow the query down from there. Fortunately, db->tree still works
for the default database format with a little care.

So om-next calls the parser, but the query will be a (focussed on the cmp) query
against the root of app-data. If you set pathopt to true and a cmp has an ident
and a query it will call the parser with the :query-root key of env to the
ident, and query to the query of the cmp, so the parser can work a bit faster.
Which I do in my parser read* fn

* Adding hooks for keys and joins in the root query for returning values and building remote query
** Principles
The standard read method of aum is db->tree of om-next. This will return a
tree of data by applying the root query over the app-state. The stock om-next
db->tree fn has been extended in the following ways:

1. It's possible to define read methods for any key anywhere in the query. If
   you do you can then return anything you want for that key. You will get in
   the env the ast for the om-next expression (join or prop), the query if it's
   a join, context-data and (app-)state. Context data is the data relevant for
   the prop or join, which depends on where in the root query the key for the
   join or prop is. For instance the default way to resolve a prop is just to do
   (get context-data key). Default way to resolve a join is db->tree on the
   query and context-data (see aum.reconciler.parser.key.route and the read
   method for [:value :route/*]).

2. The db->tree fn has been modified so that it instead of returning data it'll
   return the query again, but 'sparsified' when :sparsify-query? flag is set.
   By default if any data is found that part of the query is elided. But again
   you can add read methods to determine yourself if and what should be included
   for any key in the root query. In standard om you need to return a (possibly
   modified) ast. For these aum read methods to work you return a (modified)
   query instead. Whatever you return will be included in the remote query. If
   you want to process and modify the ast you can you just do a (om/ast->query
   ast) when you're done editing it. You can also return true which will then
   result in the query being parsed further the standard db->tree way. Note that
   currently if the key is a prop only the truthiness of the return value is
   used. If truthy the return key is included, otherwise it isn't. Return the
   full query in case of a join. So for a read method for [:aum :foo] you
   return {:foo [:some :query]}. If query had params you can add them again,
   possibly modified.

3. Read method is dispatched on key, or on [target key]. Second one takes
   preference over first. In the first instance you need to return a map such as
   {:value :some-value :aum {:some-key [:some :query]}} similar to standard
   om-next read methods.

** Examples
*** VALUE example
The method (note the :value in the dispatch vector):

#+BEGIN_SRC clojure
(defmethod aum/read [:value :bar] [{:keys [query context-data] :as env} key params] ...)
#+END_SRC

for a app state structure like this:

#+BEGIN_SRC clojure
{:foo {:bar {:k1 1 :k2 2}}}
#+END_SRC

and a root query of:

#+BEGIN_SRC clojure
[{:foo [{:bar [:k1 :k2 :k3]}]}]
#+END_SRC

receives env like this:

#+BEGIN_SRC clojure
{:query [:k1 :2]
 :context-data {:k1 1 :k2 2}
 :ast {:type :join, :dispatch-key :bar, :key :bar, :query [:k1 :k2],
       :children [{:type :prop, :dispatch-key :k1, :key :k1} {:type :prop, :dispatch-key :k2, :key :k2}]}
 ...
}
#+END_SRC

and should return for example this:

#+BEGIN_SRC clojure
{:k1 1 :k2 2}
#+END_SRC

*** REMOTE example
The method (note the :aum in the dispatch vector):

#+BEGIN_SRC clojure
(defmethod aum/read [:aum :bar] [{:keys [query context-data] :as env} key params] ...)
#+END_SRC

for a app state structure like this:

#+BEGIN_SRC clojure
{:foo {:bar {:k1 1 :k2 2}}}
#+END_SRC

and a root query of:

#+BEGIN_SRC clojure
[{:foo [{:bar [:k1 :k2 :k3]}]}]
#+END_SRC

receives env like this:

#+BEGIN_SRC clojure
{:query [:k1 :k2 :k3]
 :context-data {:k1 1 :k2 2}
 :ast {:type :join, :dispatch-key :bar, :key :bar, :query [:k1 :k2],
       :children [{:type :prop, :dispatch-key :k1, :key :k1} {:type :prop, :dispatch-key :k2, :key :k2}]}
 ...
}
#+END_SRC

and should return for example this:

#+BEGIN_SRC clojure
{:bar [:k3]}
#+END_SRC

to create a remote query like this:

#+BEGIN_SRC clojure
[{:foo [{:bar [:k3]}]}]
#+END_SRC

If you want to keep the params (or add, or modify) return something like this:

#+BEGIN_SRC clojure
(cond-> {:bar [:k3]}
  (some? params (list params)
#+END_SRC


** Notes
- If you set ignore-hooks? to true db->tree will function as the standard om-next
db->tree, but by setting :sparsify-query? to true you can still also calculate
the remote query.

- In aum.reconciler.parser.denormalize there's a comment block where you can
play around with db->tree. There's also the try-frontend-read ns.

- To see the whole process in all its glory set timbre-level to :debug in
app.config.cljs and set the chrome dev console to verbose output.

_ For read methods the parser is not available in the env, but db->tree is.

Use of that is simple:

#+BEGIN_SRC clojure
     (db->tree env {:query query ;;Apply this query
                    :data  data ;;to this data
                    :refs  app-data ;;looking up idents (refs) here.
                    :sparsify-query? false ;;Return the data, not a sparsified query
                    :ignore-hooks? false
})
#+END_SRC


* Have backend return calculated data

There are three ways to do this:

** Calculate something over a (sub)query
 Sometimes you want something to be calculated over a query and return not only
 the rows themselves, but also the extra data, such as total count. This is
 particularly tricky if you want to calculate something over a join. You want
 the joined rows, but also some more data over that particular subset of rows
 (joined as they are to the parent record).

 To do this add a :with-meta param key to the params of the query. Set this to a
 single keyword or map or a vector of them. If it's a map it should have at
 least a key :type, but you can then add more params for the calculation if you
 want.

 You can then extend the calc-meta-data multimethod from
 aum.parser.calc-meta-data in the backend which is dispatched on those
 :with-meta keys, or the :type value if it's a map. The method is called after
 the original sql query has been done. The sql-fn called, its args and
 calc-params as passed fromt the frontend.

 #+BEGIN_SRC clojure
[{:group [({:user [:id :name]} {:with-meta [:count {:type :calc2 :some :params}]})]}]
#+END_SRC

#+BEGIN_SRC clojure
(defmethod calc-meta-data :count
  [env rows {:keys [sql-fn sql-fn-args return-empty-vector? join-type calculation-params]}]
  ;;Do your calculation here
   )
#+END_SRC

One thing to take note of is that the return value for this query will be now of
the form:

#+BEGIN_SRC clojure
{:rows [[:id 1 :name "foo"]] :meta {:count 123}}
#+END_SRC

Which means you will have to take this into account when this data arrives at
your component, and/or when you implement the read method for the join with the
:with-meta param.

** Define a read key in the backend

Such as:

#+BEGIN_SRC clojure
(defmethod aum/read :calc/count
  [{:keys [user state parser query parser-config] :as env} _
   {:keys [table where] :as params}]
  ;;You can use the query to decide on what to calculate perhaps
  (timbre/info query) ;;=> [:count]
  {:value {:count (count-records env params)}})
#+END_SRC

Then add a query to a component:

#+BEGIN_SRC clojure
({:calc/count [:count]} {:table :user
                         :where [:id :< 5]})
#+END_SRC

Disadvantage of this method is that you can only use this query as a root query
or quasi root query. Also you have to possibly duplicate the params of this query in the
frontend from another query. And this isn't useful for a joined query.

** Redirect a read to a custom-read
Used search translations. Idea is to set a :custom-read key in the params of a
query. Backend will use the read method as set to the :custom-read key and pass
in the rest of params as well.

Advantage of this is that you can redirect a query for a join to your own read
method. Where you can then return a calculated value, any rows queried for
and/or any other data you like.

#+BEGIN_SRC clojure
(defmethod aum/read :count-records
  [{:keys [user state parser query parser-config] :as env} _
   {:keys [table where] :as params}]
  {:value (count-records env params)})
#+END_SRC

With this query:

#+BEGIN_SRC clojure
'({:user-count [:count]} {:custom-read :count-records
                          :table :user
                          :where [:id :< 5]})
#+END_SRC


* invalidation
On save of eg a dossier type:
(bu/get-key-in-page-state @state :dossier-type :validate)
invalidated-fields (bu/calc-invalidations dossier-type validate)

(if (seq invalidated-fields)
  (bu/set-key-in-page-state state :dossier-type :invalidated-fields invalidated-fields))

So on save you fetch validate map for the relevant record type
You give the record and the validate map to calc-invalidations

For every key in record calc-invalidations calls the validated? fn of the value
map of the same key in the validate map and sets the [:invalidated? :prop] key in the
validate map to true and returns it.

So in page-state:

#+BEGIN_SRC clojure
{:route/dossier-types {:table {:dossier-type {:validate {:name validate-name-map
                                                         :some-other-prop validate-some-other-prop}
                                               :invalidated-fields {:name {:invalidated? {} :message ""}
}}}}
#+END_SRC

You then set a key called :invalidated-fields in page state to that validate
map. Which you can pick up in your components and use it to modify the ui if
needed (show in red, show error message etc)
